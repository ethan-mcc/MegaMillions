{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "5d540182-371c-400a-a0ea-2a6d9f3e09c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Draw Date</th>\n",
       "      <th>Winning Numbers</th>\n",
       "      <th>Mega Ball</th>\n",
       "      <th>Multiplier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/19/2018</td>\n",
       "      <td>15 23 53 65 70</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10/19/2018</td>\n",
       "      <td>15 23 53 65 70</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10/19/2018</td>\n",
       "      <td>15 23 53 65 70</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10/19/2021</td>\n",
       "      <td>03 12 13 19 52</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10/19/2021</td>\n",
       "      <td>03 12 13 19 52</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>12/31/2019</td>\n",
       "      <td>30 44 49 53 56</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>12/31/2019</td>\n",
       "      <td>30 44 49 53 56</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>12/31/2021</td>\n",
       "      <td>02 05 30 46 61</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>12/31/2021</td>\n",
       "      <td>02 05 30 46 61</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>12/31/2021</td>\n",
       "      <td>02 05 30 46 61</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>633 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Draw Date Winning Numbers  Mega Ball  Multiplier\n",
       "0    10/19/2018  15 23 53 65 70          7           2\n",
       "1    10/19/2018  15 23 53 65 70          7           2\n",
       "2    10/19/2018  15 23 53 65 70          7           2\n",
       "3    10/19/2021  03 12 13 19 52          1           3\n",
       "4    10/19/2021  03 12 13 19 52          1           3\n",
       "..          ...             ...        ...         ...\n",
       "628  12/31/2019  30 44 49 53 56         11           3\n",
       "629  12/31/2019  30 44 49 53 56         11           3\n",
       "630  12/31/2021  02 05 30 46 61          8           3\n",
       "631  12/31/2021  02 05 30 46 61          8           3\n",
       "632  12/31/2021  02 05 30 46 61          8           3\n",
       "\n",
       "[633 rows x 4 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# pip install \"gluonts[torch]\"\n",
    "\n",
    "# Connect to the SQLite database for training data\n",
    "train_conn = sqlite3.connect('MegaMillions_Train.db')\n",
    "\n",
    "# Query data from the database for training\n",
    "query_train = \"SELECT * FROM Interval_Data\"\n",
    "df_train = pd.read_sql_query(query_train, train_conn)\n",
    "df_train\n",
    "\n",
    "# Connect to the SQLite database for test data\n",
    "test_conn = sqlite3.connect('MegaMillions_Test.db')\n",
    "\n",
    "# Query data from the database for test\n",
    "query_test = \"SELECT * FROM Interval_Data\"\n",
    "df_test = pd.read_sql_query(query_test, test_conn)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "170bd4a5-4cd4-4e1d-b11a-9b252efe32e3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "C:\\Users\\Ethan\\PycharmProjects\\pythonProject6\\venv\\lib\\site-packages\\lightning\\pytorch\\trainer\\configuration_validator.py:74: You defined a `validation_step` but have no `val_dataloader`. Skipping val loop.\n",
      "\n",
      "  | Name  | Type        | Params | In sizes                                                        | Out sizes  \n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "0 | model | DeepARModel | 39.0 K | [[1, 1], [1, 1], [1, 1122, 4], [1, 1122], [1, 1122], [1, 6, 4]] | [1, 100, 6]\n",
      "----------------------------------------------------------------------------------------------------------------------\n",
      "39.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "39.0 K    Total params\n",
      "0.156     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd9794959a9d4b0f9a20a6e389330111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                                                                                   …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 50: 'train_loss' reached 8.17453 (best 8.17453), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=0-step=50.ckpt' as top 1\n",
      "Epoch 1, global step 100: 'train_loss' reached 6.76985 (best 6.76985), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=1-step=100.ckpt' as top 1\n",
      "Epoch 2, global step 150: 'train_loss' reached 6.60185 (best 6.60185), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=2-step=150.ckpt' as top 1\n",
      "Epoch 3, global step 200: 'train_loss' reached 6.54581 (best 6.54581), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=3-step=200.ckpt' as top 1\n",
      "Epoch 4, global step 250: 'train_loss' reached 6.46320 (best 6.46320), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=4-step=250.ckpt' as top 1\n",
      "Epoch 5, global step 300: 'train_loss' reached 6.42735 (best 6.42735), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=5-step=300.ckpt' as top 1\n",
      "Epoch 6, global step 350: 'train_loss' reached 6.39284 (best 6.39284), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=6-step=350.ckpt' as top 1\n",
      "Epoch 7, global step 400: 'train_loss' reached 6.34274 (best 6.34274), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=7-step=400.ckpt' as top 1\n",
      "Epoch 8, global step 450: 'train_loss' reached 6.33997 (best 6.33997), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=8-step=450.ckpt' as top 1\n",
      "Epoch 9, global step 500: 'train_loss' reached 6.29555 (best 6.29555), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=9-step=500.ckpt' as top 1\n",
      "Epoch 10, global step 550: 'train_loss' reached 6.26017 (best 6.26017), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=10-step=550.ckpt' as top 1\n",
      "Epoch 11, global step 600: 'train_loss' was not in top 1\n",
      "Epoch 12, global step 650: 'train_loss' reached 6.22983 (best 6.22983), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=12-step=650.ckpt' as top 1\n",
      "Epoch 13, global step 700: 'train_loss' reached 6.20257 (best 6.20257), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=13-step=700.ckpt' as top 1\n",
      "Epoch 14, global step 750: 'train_loss' was not in top 1\n",
      "Epoch 15, global step 800: 'train_loss' reached 6.18315 (best 6.18315), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=15-step=800.ckpt' as top 1\n",
      "Epoch 16, global step 850: 'train_loss' reached 6.16830 (best 6.16830), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=16-step=850.ckpt' as top 1\n",
      "Epoch 17, global step 900: 'train_loss' reached 6.16015 (best 6.16015), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=17-step=900.ckpt' as top 1\n",
      "Epoch 18, global step 950: 'train_loss' reached 6.12482 (best 6.12482), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=18-step=950.ckpt' as top 1\n",
      "Epoch 19, global step 1000: 'train_loss' was not in top 1\n",
      "Epoch 20, global step 1050: 'train_loss' reached 6.10895 (best 6.10895), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=20-step=1050.ckpt' as top 1\n",
      "Epoch 21, global step 1100: 'train_loss' reached 6.08512 (best 6.08512), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=21-step=1100.ckpt' as top 1\n",
      "Epoch 22, global step 1150: 'train_loss' was not in top 1\n",
      "Epoch 23, global step 1200: 'train_loss' reached 6.06682 (best 6.06682), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=23-step=1200.ckpt' as top 1\n",
      "Epoch 24, global step 1250: 'train_loss' was not in top 1\n",
      "Epoch 25, global step 1300: 'train_loss' reached 6.06302 (best 6.06302), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=25-step=1300.ckpt' as top 1\n",
      "Epoch 26, global step 1350: 'train_loss' reached 6.04540 (best 6.04540), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=26-step=1350.ckpt' as top 1\n",
      "Epoch 27, global step 1400: 'train_loss' was not in top 1\n",
      "Epoch 28, global step 1450: 'train_loss' reached 6.02371 (best 6.02371), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=28-step=1450.ckpt' as top 1\n",
      "Epoch 29, global step 1500: 'train_loss' reached 6.00834 (best 6.00834), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=29-step=1500.ckpt' as top 1\n",
      "Epoch 30, global step 1550: 'train_loss' was not in top 1\n",
      "Epoch 31, global step 1600: 'train_loss' reached 5.99980 (best 5.99980), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=31-step=1600.ckpt' as top 1\n",
      "Epoch 32, global step 1650: 'train_loss' reached 5.97692 (best 5.97692), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=32-step=1650.ckpt' as top 1\n",
      "Epoch 33, global step 1700: 'train_loss' was not in top 1\n",
      "Epoch 34, global step 1750: 'train_loss' reached 5.97304 (best 5.97304), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=34-step=1750.ckpt' as top 1\n",
      "Epoch 35, global step 1800: 'train_loss' reached 5.96709 (best 5.96709), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=35-step=1800.ckpt' as top 1\n",
      "Epoch 36, global step 1850: 'train_loss' was not in top 1\n",
      "Epoch 37, global step 1900: 'train_loss' reached 5.94463 (best 5.94463), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=37-step=1900.ckpt' as top 1\n",
      "Epoch 38, global step 1950: 'train_loss' was not in top 1\n",
      "Epoch 39, global step 2000: 'train_loss' reached 5.93294 (best 5.93294), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=39-step=2000.ckpt' as top 1\n",
      "Epoch 40, global step 2050: 'train_loss' reached 5.92427 (best 5.92427), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=40-step=2050.ckpt' as top 1\n",
      "Epoch 41, global step 2100: 'train_loss' was not in top 1\n",
      "Epoch 42, global step 2150: 'train_loss' reached 5.91848 (best 5.91848), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=42-step=2150.ckpt' as top 1\n",
      "Epoch 43, global step 2200: 'train_loss' reached 5.89780 (best 5.89780), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=43-step=2200.ckpt' as top 1\n",
      "Epoch 44, global step 2250: 'train_loss' was not in top 1\n",
      "Epoch 45, global step 2300: 'train_loss' reached 5.89616 (best 5.89616), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=45-step=2300.ckpt' as top 1\n",
      "Epoch 46, global step 2350: 'train_loss' reached 5.89046 (best 5.89046), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=46-step=2350.ckpt' as top 1\n",
      "Epoch 47, global step 2400: 'train_loss' was not in top 1\n",
      "Epoch 48, global step 2450: 'train_loss' reached 5.86847 (best 5.86847), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=48-step=2450.ckpt' as top 1\n",
      "Epoch 49, global step 2500: 'train_loss' was not in top 1\n",
      "Epoch 50, global step 2550: 'train_loss' reached 5.86547 (best 5.86547), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=50-step=2550.ckpt' as top 1\n",
      "Epoch 51, global step 2600: 'train_loss' reached 5.85100 (best 5.85100), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=51-step=2600.ckpt' as top 1\n",
      "Epoch 52, global step 2650: 'train_loss' was not in top 1\n",
      "Epoch 53, global step 2700: 'train_loss' reached 5.84356 (best 5.84356), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=53-step=2700.ckpt' as top 1\n",
      "Epoch 54, global step 2750: 'train_loss' was not in top 1\n",
      "Epoch 55, global step 2800: 'train_loss' was not in top 1\n",
      "Epoch 56, global step 2850: 'train_loss' reached 5.82524 (best 5.82524), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=56-step=2850.ckpt' as top 1\n",
      "Epoch 57, global step 2900: 'train_loss' was not in top 1\n",
      "Epoch 58, global step 2950: 'train_loss' reached 5.82073 (best 5.82073), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=58-step=2950.ckpt' as top 1\n",
      "Epoch 59, global step 3000: 'train_loss' reached 5.80436 (best 5.80436), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=59-step=3000.ckpt' as top 1\n",
      "Epoch 60, global step 3050: 'train_loss' was not in top 1\n",
      "Epoch 61, global step 3100: 'train_loss' reached 5.80358 (best 5.80358), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=61-step=3100.ckpt' as top 1\n",
      "Epoch 62, global step 3150: 'train_loss' reached 5.79025 (best 5.79025), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=62-step=3150.ckpt' as top 1\n",
      "Epoch 63, global step 3200: 'train_loss' was not in top 1\n",
      "Epoch 64, global step 3250: 'train_loss' was not in top 1\n",
      "Epoch 65, global step 3300: 'train_loss' reached 5.78803 (best 5.78803), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=65-step=3300.ckpt' as top 1\n",
      "Epoch 66, global step 3350: 'train_loss' was not in top 1\n",
      "Epoch 67, global step 3400: 'train_loss' reached 5.76399 (best 5.76399), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=67-step=3400.ckpt' as top 1\n",
      "Epoch 68, global step 3450: 'train_loss' was not in top 1\n",
      "Epoch 69, global step 3500: 'train_loss' reached 5.76317 (best 5.76317), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=69-step=3500.ckpt' as top 1\n",
      "Epoch 70, global step 3550: 'train_loss' reached 5.74763 (best 5.74763), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=70-step=3550.ckpt' as top 1\n",
      "Epoch 71, global step 3600: 'train_loss' was not in top 1\n",
      "Epoch 72, global step 3650: 'train_loss' reached 5.74214 (best 5.74214), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=72-step=3650.ckpt' as top 1\n",
      "Epoch 73, global step 3700: 'train_loss' was not in top 1\n",
      "Epoch 74, global step 3750: 'train_loss' was not in top 1\n",
      "Epoch 75, global step 3800: 'train_loss' reached 5.73741 (best 5.73741), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=75-step=3800.ckpt' as top 1\n",
      "Epoch 76, global step 3850: 'train_loss' was not in top 1\n",
      "Epoch 77, global step 3900: 'train_loss' reached 5.72570 (best 5.72570), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=77-step=3900.ckpt' as top 1\n",
      "Epoch 78, global step 3950: 'train_loss' reached 5.71527 (best 5.71527), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=78-step=3950.ckpt' as top 1\n",
      "Epoch 79, global step 4000: 'train_loss' was not in top 1\n",
      "Epoch 80, global step 4050: 'train_loss' was not in top 1\n",
      "Epoch 81, global step 4100: 'train_loss' reached 5.69667 (best 5.69667), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=81-step=4100.ckpt' as top 1\n",
      "Epoch 82, global step 4150: 'train_loss' was not in top 1\n",
      "Epoch 83, global step 4200: 'train_loss' was not in top 1\n",
      "Epoch 84, global step 4250: 'train_loss' reached 5.69619 (best 5.69619), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=84-step=4250.ckpt' as top 1\n",
      "Epoch 85, global step 4300: 'train_loss' was not in top 1\n",
      "Epoch 86, global step 4350: 'train_loss' reached 5.68202 (best 5.68202), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=86-step=4350.ckpt' as top 1\n",
      "Epoch 87, global step 4400: 'train_loss' was not in top 1\n",
      "Epoch 88, global step 4450: 'train_loss' reached 5.67729 (best 5.67729), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=88-step=4450.ckpt' as top 1\n",
      "Epoch 89, global step 4500: 'train_loss' reached 5.67084 (best 5.67084), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=89-step=4500.ckpt' as top 1\n",
      "Epoch 90, global step 4550: 'train_loss' was not in top 1\n",
      "Epoch 91, global step 4600: 'train_loss' reached 5.67045 (best 5.67045), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=91-step=4600.ckpt' as top 1\n",
      "Epoch 92, global step 4650: 'train_loss' reached 5.65286 (best 5.65286), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=92-step=4650.ckpt' as top 1\n",
      "Epoch 93, global step 4700: 'train_loss' was not in top 1\n",
      "Epoch 94, global step 4750: 'train_loss' was not in top 1\n",
      "Epoch 95, global step 4800: 'train_loss' reached 5.65217 (best 5.65217), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=95-step=4800.ckpt' as top 1\n",
      "Epoch 96, global step 4850: 'train_loss' was not in top 1\n",
      "Epoch 97, global step 4900: 'train_loss' reached 5.63515 (best 5.63515), saving model to 'C:\\\\Users\\\\Ethan\\\\PycharmProjects\\\\MegaMillionsProject\\\\lightning_logs\\\\version_19\\\\checkpoints\\\\epoch=97-step=4900.ckpt' as top 1\n",
      "Epoch 98, global step 4950: 'train_loss' was not in top 1\n",
      "Epoch 99, global step 5000: 'train_loss' was not in top 1\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n",
      "Running evaluation: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2529/2529 [00:13<00:00, 188.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for White Balls and Mega Ball: nan\n",
      "MSE for White Balls and Mega Ball: 0.2998087633068742\n",
      "RMSE for White Balls and Mega Ball: 0.5475479552576872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\Ethan\\PycharmProjects\\pythonProject6\\venv\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:134: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "C:\\Users\\Ethan\\PycharmProjects\\pythonProject6\\venv\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:134: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "C:\\Users\\Ethan\\PycharmProjects\\pythonProject6\\venv\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:134: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n"
     ]
    }
   ],
   "source": [
    "from gluonts.dataset.common import ListDataset\n",
    "from gluonts.torch.model.deepar import DeepAREstimator\n",
    "from gluonts.evaluation import make_evaluation_predictions, Evaluator\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# pip install \"gluonts[torch]\"\n",
    "\n",
    "# Convert 'Draw Date' to datetime\n",
    "df_train['Draw Date'] = pd.to_datetime(df_train['Draw Date'])\n",
    "\n",
    "# Prepare DataFrame for predicting Winning Numbers\n",
    "winning_numbers = df_train['Winning Numbers'].str.split(' ', expand=True)\n",
    "winning_numbers.columns = [f'Ball_{i+1}' for i in winning_numbers.columns]\n",
    "df_train = pd.concat([df_train, winning_numbers], axis=1)\n",
    "\n",
    "# Prepare data for predicting Winning Numbers and Mega Ball\n",
    "winning_numbers_df = df_train[['Draw Date'] + [f'Ball_{i+1}' for i in range(5)] + ['Mega Ball']].copy()\n",
    "winning_numbers_df.columns = ['ds'] + [f'y_{i+1}' for i in range(5)] + ['y_mega_ball']  # Rename columns\n",
    "\n",
    "# Min-Max scaling for the numerical columns\n",
    "scaler = MinMaxScaler()\n",
    "numerical_columns = [f'y_{i+1}' for i in range(5)] + ['y_mega_ball']\n",
    "winning_numbers_df[numerical_columns] = scaler.fit_transform(winning_numbers_df[numerical_columns])\n",
    "\n",
    "# Create a ListDataset for multiple values prediction using the scaled data\n",
    "data = [\n",
    "    {\n",
    "        \"start\": winning_numbers_df.iloc[i]['ds'],\n",
    "        \"target\": winning_numbers_df.iloc[i][numerical_columns].values,\n",
    "        \"feat_dynamic_real\": [[None] * 6]  \n",
    "    }\n",
    "    for i in range(len(winning_numbers_df))\n",
    "]\n",
    "\n",
    "# Frequency of data \n",
    "freq = \"D\"\n",
    "\n",
    "# Create ListDataset\n",
    "train_ds = ListDataset(data, freq=freq)\n",
    "\n",
    "# Define DeepAR estimator for predicting 5 white balls and 1 Mega Ball\n",
    "estimator = DeepAREstimator(prediction_length=6, freq=freq, context_length=30, num_layers=3)\n",
    "\n",
    "# Train the model\n",
    "predictor = estimator.train(training_data=train_ds)\n",
    "\n",
    "# Make predictions for Winning Numbers and Mega Ball\n",
    "forecast_it, ts_it = make_evaluation_predictions(dataset=train_ds, predictor=predictor, num_samples=10)\n",
    "\n",
    "forecasts = list(forecast_it)\n",
    "tss = list(ts_it)\n",
    "\n",
    "# Calculate metrics\n",
    "evaluator = Evaluator()\n",
    "agg_metrics, item_metrics = evaluator(tss, forecasts, num_series=len(train_ds))\n",
    "\n",
    "mae_white_balls = agg_metrics[\"MASE\"]\n",
    "mse_white_balls = agg_metrics[\"MSE\"]\n",
    "rmse_white_balls = agg_metrics[\"RMSE\"]\n",
    "\n",
    "print(f\"MAE for White Balls and Mega Ball: {mae_white_balls}\")\n",
    "print(f\"MSE for White Balls and Mega Ball: {mse_white_balls}\")\n",
    "print(f\"RMSE for White Balls and Mega Ball: {rmse_white_balls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "131b3613-a698-4114-8ac2-2dc2569bc550",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running evaluation: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 633/633 [00:03<00:00, 169.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE for White Balls on test data: nan\n",
      "MSE for White Balls on test data: 1354.691943127962\n",
      "RMSE for White Balls on test data: 36.806140019403855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\Ethan\\PycharmProjects\\pythonProject6\\venv\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:134: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "C:\\Users\\Ethan\\PycharmProjects\\pythonProject6\\venv\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:134: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n",
      "C:\\Users\\Ethan\\PycharmProjects\\pythonProject6\\venv\\lib\\site-packages\\pandas\\core\\dtypes\\astype.py:134: UserWarning: Warning: converting a masked element to nan.\n",
      "  return arr.astype(dtype, copy=True)\n"
     ]
    }
   ],
   "source": [
    "'''# Convert 'Draw Date' to datetime\n",
    "df_test['Draw Date'] = pd.to_datetime(df_test['Draw Date'])\n",
    "\n",
    "# Split the 'Winning Numbers' into separate columns for white balls\n",
    "winning_numbers_test = df_test['Winning Numbers'].str.split(' ', expand=True)\n",
    "winning_numbers_test.columns = [f'Ball_{i+1}' for i in winning_numbers_test.columns]\n",
    "df_test = pd.concat([df_test, winning_numbers_test], axis=1)\n",
    "\n",
    "# Convert 'Ball' columns to integers\n",
    "ball_columns_test = [f'Ball_{i+1}' for i in range(5)]  # Assuming 5 white balls\n",
    "for col in ball_columns_test:\n",
    "    df_test[col] = pd.to_numeric(df_test[col])\n",
    "\n",
    "# Prepare data for predicting Winning Numbers and Mega Ball on test data\n",
    "test_data = df_test[['Draw Date'] + ball_columns_test + ['Mega Ball']].copy()\n",
    "test_data.columns = ['ds'] + [f'y_{i+1}' for i in range(5)] + ['y_mega_ball']  # Rename columns\n",
    "\n",
    "# Create a ListDataset for the test data including white balls and Mega Ball\n",
    "test_data_list = [\n",
    "    {\n",
    "        \"start\": test_data.iloc[i]['ds'],\n",
    "        \"target\": test_data.iloc[i][[f'y_{i+1}' for i in range(5)] + ['y_mega_ball']].values,\n",
    "        \"feat_dynamic_real\": [[None] * 6]  # 2D array of Nones for features (if any)\n",
    "    }\n",
    "    for i in range(len(test_data))\n",
    "]\n",
    "\n",
    "# Frequency of data (assuming daily frequency)\n",
    "freq = \"D\"\n",
    "\n",
    "# Create ListDataset for the test data\n",
    "test_ds = ListDataset(test_data_list, freq=freq)\n",
    "\n",
    "# Use the trained predictor to make predictions on the test data\n",
    "forecast_it_test, ts_it_test = make_evaluation_predictions(\n",
    "    dataset=test_ds,\n",
    "    predictor=predictor,\n",
    "    num_samples=100  # Number of sample paths to draw while making predictions\n",
    ")\n",
    "\n",
    "forecasts_test = list(forecast_it_test)\n",
    "tss_test = list(ts_it_test)\n",
    "# Calculate metrics or perform any analysis needed for evaluation\n",
    "evaluator = Evaluator()\n",
    "agg_metrics_test, item_metrics_test = evaluator(iter(tss_test), iter(forecasts_test), num_series=len(test_ds))\n",
    "\n",
    "# Retrieve metrics for white balls and Mega Ball from the test data evaluation\n",
    "mae_white_balls_test = agg_metrics_test[\"MASE\"]\n",
    "mse_white_balls_test = agg_metrics_test[\"MSE\"]\n",
    "rmse_white_balls_test = agg_metrics_test[\"RMSE\"]\n",
    "\n",
    "print(f\"MAE for White Balls on test data: {mae_white_balls_test}\")\n",
    "print(f\"MSE for White Balls on test data: {mse_white_balls_test}\")\n",
    "print(f\"RMSE for White Balls on test data: {rmse_white_balls_test}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3f580fbf-055f-4c74-afac-e81f30f51241",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Mega Ball number for 2023-12-31: -1.3140626087260188e-10\n"
     ]
    }
   ],
   "source": [
    "def predict_mega_ball(model, date):\n",
    "    # Prepare data for prediction based on the provided date\n",
    "    prediction_data = pd.DataFrame({'ds': [date], 'y': [0]})  # Replace 0 with a default value for prediction\n",
    "\n",
    "    # Convert 'ds' column to datetime\n",
    "    prediction_data['ds'] = pd.to_datetime(prediction_data['ds'])\n",
    "\n",
    "    # Create a ListDataset for prediction\n",
    "    prediction_ds = ListDataset(\n",
    "        [\n",
    "            {\n",
    "                \"start\": prediction_data[\"ds\"].values[0],  # Assuming a single time series\n",
    "                \"target\": prediction_data[\"y\"].values,\n",
    "                \"feat_dynamic_real\": [[None]]  # 2D array of a single None\n",
    "            }\n",
    "        ],\n",
    "        freq=\"D\"\n",
    "    )\n",
    "\n",
    "    # Make prediction using the provided model\n",
    "    forecast_it_pred = model.predict(prediction_ds)\n",
    "\n",
    "    # Extract the predicted value for the Mega Ball\n",
    "    forecast = next(forecast_it_pred)\n",
    "    predicted_mega_ball = forecast.mean[0]\n",
    "\n",
    "    return predicted_mega_ball\n",
    "\n",
    "\n",
    "\n",
    "predicted_number = predict_mega_ball(predictor, '2023-12-31')  \n",
    "print(f\"Predicted Mega Ball number for 2023-12-31: {predicted_number}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "e7d2cbc1-8bac-40f7-a1f5-437331810aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled Combined Predictions: [[ 1.7714401e-09  6.7203447e-09 -5.6036285e-08 -1.9172457e-08\n",
      "   1.2283897e-08 -2.0033717e-08]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Frequency of data \n",
    "freq = \"D\"\n",
    "\n",
    "# Create a ListDataset for the input date prediction\n",
    "def predict_numbers(input_date):\n",
    "    prediction_data = [\n",
    "        {\n",
    "            \"start\": input_date,\n",
    "            \"target\": [None, None, None, None, None, None],  # Placeholder for predictions\n",
    "            \"feat_dynamic_real\": [[None] * 6]  \n",
    "        }\n",
    "    ]\n",
    "\n",
    "    predict_ds = ListDataset(prediction_data, freq=freq)\n",
    "\n",
    "    # Make predictions for the input date\n",
    "    forecast_it, ts_it = make_evaluation_predictions(dataset=predict_ds, predictor=predictor, num_samples=10)\n",
    "\n",
    "    forecasts = list(forecast_it)\n",
    "    tss = list(ts_it)\n",
    "\n",
    "    # Return the predicted values for white balls and Mega Ball\n",
    "    return forecasts[0].samples.mean(axis=0)[:5], forecasts[0].samples.mean(axis=0)[-1]\n",
    "\n",
    "input_date = pd.to_datetime('2023-12-1')\n",
    "white_balls_pred, mega_ball_pred = predict_numbers(input_date)\n",
    "\n",
    "# Assuming white_balls_pred and mega_ball_pred are the predicted values\n",
    "combined_predictions = np.concatenate((white_balls_pred, np.array([mega_ball_pred])))\n",
    "\n",
    "# Reshape the combined predictions array to fit the scaler\n",
    "combined_predictions = combined_predictions.reshape(1, -1)\n",
    "\n",
    "\n",
    "# Fit the scaler on the combined predictions\n",
    "scaler.fit(combined_predictions)\n",
    "\n",
    "# Scale the combined predictions\n",
    "scaled_combined_predictions = combined_scaler.transform(combined_predictions)\n",
    "\n",
    "# Now, you have the combined and scaled predictions\n",
    "print(f\"Scaled Combined Predictions: {scaled_combined_predictions}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56783625-5973-46ca-8792-1c699915f54b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
